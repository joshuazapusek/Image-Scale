{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Identifying Reference Object in Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://dev.to/erol/object-detection-with-color-knl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 16\n",
    "pts = deque(maxlen=buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using HSV: Hue, Saturation and Value for representing color in images to then detect\n",
    "# Define upper and lower thresholds for the reference object in hsv\n",
    "# ref_lower = (0, 0, 150)\n",
    "# ref_upper = (255, 20, 255)\n",
    "\n",
    "ref_lower = (0, 0, 0)\n",
    "ref_upper = (255, 70, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"C:/Users/jzapu/Image_Scaling/blackout.jpg\")\n",
    "# imaget = cv2.imread(\"C:/Users/jzapu/Image_Scaling/img2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = cv2.putText(imaget, \"HELLO\", (25, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 0, 0), 3)\n",
    "# cv2.imwrite(\"output.jpg\", out)\n",
    "cv2.imshow(\"TEST\", new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See\n",
    "cv2.imshow(\"Test Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be applying gaussian smoothing, then HSV conversion, then opening (Erosian -> Dilation) to preprocess image for targeting\n",
    "# Gaussian Operation\n",
    "blur_image = cv2.GaussianBlur(image, (11, 11), 0)\n",
    "# RGB -> HSV\n",
    "hsv = cv2.cvtColor(blur_image, cv2.COLOR_BGR2HSV)\n",
    "# Morphology: Opening Image\n",
    "# Define Mask for Operation\n",
    "mask = cv2.inRange(hsv, ref_lower, ref_upper)\n",
    "mask = cv2.erode(mask, None, iterations=2)\n",
    "mask = cv2.dilate(mask, None, iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now noise is gone: find edges of reference object (all edges)\n",
    "contours,_ = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "center = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3281, 2152) ((3031.69384765625, 2063.304931640625), (2013.5504150390625, 681.5897827148438), 1.4714945554733276)\n"
     ]
    }
   ],
   "source": [
    "# Find coordinates in image to draw the target shape outline\n",
    "if (len(contours) > 0):\n",
    "    target = max(contours, key=cv2.contourArea)\n",
    "    # (x,y), radius = cv2.minEnclosingCircle(target)\n",
    "    rect = cv2.minAreaRect(target)\n",
    "    # center = (int(x),int(y))\n",
    "    # radius = int(radius)\n",
    "    ((x,y), (width, height), rotation) = rect\n",
    "    s = f\"x {np.round(x)}, y: {np.round(y)}, width: {np.round(width)}, height: {np.round(height)}, rotation: {np.round(rotation)}\"\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int64(box)\n",
    "    M = cv2.moments(target)\n",
    "    center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "    # out = cv2.circle(image, center, radius, (0, 255, 0), 4)\n",
    "    cv2.circle(image, center, 5, (255, 0, 255), -1)\n",
    "    cv2.drawContours(image, [box], 0, (255, 0, 0), 4)\n",
    "    fin =  cv2.putText(image, s, (25, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (200, 0, 50), 2)\n",
    "    cv2.imwrite('testout.jpg', fin)\n",
    "    cv2.imshow(\"TEST\", fin)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    print(center, rect)\n",
    "else:\n",
    "    print(\"Error with thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_windows = 0\n",
    "rect_arr = []\n",
    "box_arr = []\n",
    "for i in range(len(contours)):\n",
    "    target = max(contours, key=cv2.contourArea)\n",
    "    num_windows = num_windows + 1\n",
    "    rect = cv2.minAreaRect(contours[i])\n",
    "    rect_arr.append(rect)\n",
    "    ((x,y), (width, height), rotation) = rect\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int64(box)\n",
    "    box_arr.append(box)\n",
    "    M = cv2.moments(target)\n",
    "    center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "    #cv2.circle(image, center, 5, (255, 0, 255), -1)\n",
    "    cv2.drawContours(image, [box], 0, (255, 0, 0), 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Wight and Height of the reference in pixels\n",
    "refWidth = 3.0\n",
    "refHeight = 4.0\n",
    "\n",
    "# Width and Height Ratios from last time - NOT ACCURATE HERE WILL NEED TO CAHNGE LATER\n",
    "widthRatio = 0.003\n",
    "heightRatio = 0.0063"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 3.15\n"
     ]
    }
   ],
   "source": [
    "# Get Total length and width of the side\n",
    "#############################################\n",
    "# Dims of image\n",
    "rows, cols, ch = image.shape\n",
    "sideHeight = heightRatio * cols\n",
    "sideWidth = widthRatio * rows\n",
    "print(sideWidth, sideHeight)\n",
    "\n",
    "# Draw Lines\n",
    "image = cv2.line(image, (0, 0), (0, 500), (0, 255, 255), 2)\n",
    "image = cv2.line(image, (0, 0), (500, 0), (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[[ 43 443]\n",
      " [ 47 443]\n",
      " [ 47 449]\n",
      " [ 43 449]]\n",
      "[[363 267]\n",
      " [449 265]\n",
      " [454 456]\n",
      " [368 458]]\n",
      "43 47\n"
     ]
    }
   ],
   "source": [
    "# Get end-of-image to first / last window distance\n",
    "# First Window:\n",
    "print(num_windows)\n",
    "print(box_arr[0])\n",
    "print(box_arr[3])\n",
    "left_padding = box_arr[0][0][0] - 0\n",
    "# Last Window\n",
    "right_padding = cols - box_arr[2][1][0] \n",
    "# NOTE: Looks like cv2 going CCW with the box points \n",
    "print(left_padding, right_padding)\n",
    "\n",
    "# Draw Lines\n",
    "left_start_point = (0, box_arr[0][0][1])\n",
    "left_end_point = (box_arr[0][0][0], box_arr[0][0][1])\n",
    "right_start_point = (cols, box_arr[2][1][1])\n",
    "right_end_point = (box_arr[2][1][0], box_arr[2][1][1])\n",
    "image = cv2.line(image, left_start_point, left_end_point, (0, 255, 255), 2)\n",
    "image = cv2.line(image, right_start_point, right_end_point, (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Top - bottom distance (top / bottom of image - to - window blackout)\n",
    "bottom_padding = cols - box_arr[0][2][1]\n",
    "top_padding = box_arr[0][2][1] - 0\n",
    "\n",
    "# Draw Lines\n",
    "\n",
    "image = cv2.line(image, (box_arr[3][0][0], 0), (box_arr[3][0][0], box_arr[3][0][1]), (0, 255, 255), 2)\n",
    "image = cv2.line(image, (box_arr[3][0][0], box_arr[3][3][1]), (box_arr[3][0][0], cols), (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Distance between windows \n",
    "# MAP\n",
    "# arr[4] -> 1\n",
    "# arr[6] -> 2\n",
    "# arr[3] -> 3\n",
    "\n",
    "d1 = box_arr[6][0][0] - box_arr[4][1][0]\n",
    "d2 = box_arr[3][0][0] - box_arr[6][1][0]\n",
    "image = cv2.line(image, (box_arr[4][1][0], box_arr[4][1][1]), (box_arr[6][0][0], box_arr[6][0][1]), (0, 255, 255), 2)\n",
    "image = cv2.line(image, (box_arr[6][1][0], box_arr[6][1][1]), (box_arr[3][0][0], box_arr[3][0][1]), (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHow and Save\n",
    "cv2.imshow(\"TEST\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#cv2.imwrite('LinesDrawn.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('Windows Space Determined', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.imwrite('windowOut.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43 443]\n",
      " [ 47 443]\n",
      " [ 47 449]\n",
      " [ 43 449]]\n",
      "[[ 43 383]\n",
      " [ 47 383]\n",
      " [ 47 388]\n",
      " [ 43 388]]\n",
      "[[448 270]\n",
      " [453 270]\n",
      " [453 274]\n",
      " [448 274]]\n",
      "[[363 267]\n",
      " [449 265]\n",
      " [454 456]\n",
      " [368 458]]\n",
      "[[ 47 261]\n",
      " [132 261]\n",
      " [132 458]\n",
      " [ 47 458]]\n",
      "[[439 260]\n",
      " [443 260]\n",
      " [443 264]\n",
      " [439 264]]\n",
      "[[207 255]\n",
      " [295 255]\n",
      " [295 452]\n",
      " [207 452]]\n"
     ]
    }
   ],
   "source": [
    "print(box_arr[0])\n",
    "print(box_arr[1])\n",
    "print(box_arr[2])\n",
    "print(box_arr[3])\n",
    "print(box_arr[4])\n",
    "print(box_arr[5])\n",
    "print(box_arr[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3770 2501\n"
     ]
    }
   ],
   "source": [
    "# Perspective transform\n",
    "# NOTE: MAY WANT TO ADD A ROTATION IF ON A SLANT LIKE IN THIS IMAGE\n",
    "\n",
    "# Dims of image\n",
    "rows, cols, ch = image.shape\n",
    "\n",
    "print (rows, cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030110388831515737 0.0062926639901208555\n"
     ]
    }
   ],
   "source": [
    "# Get feet / pixel value for reference - use for getting full image \n",
    "pwidth = rect[1][0]\n",
    "pheight = rect[1][1]\n",
    "# Calculate the Feet / Pixel\n",
    "wratio = refWidth / pwidth\n",
    "hratio = refHeight / pheight\n",
    "\n",
    "print(wratio, hratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.351616589481432 15.73795263929226\n"
     ]
    }
   ],
   "source": [
    "# Output length and width of wall\n",
    "sideHeight = hratio * cols\n",
    "sideWidth = wratio * rows\n",
    "print(sideWidth, sideHeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1376 2434]\n",
      " [2011 2413]\n",
      " [2045 3408]\n",
      " [1409 3430]]\n"
     ]
    }
   ],
   "source": [
    "print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.72887730e-03  1.61589777e-04  9.11985612e+00]\n",
      " [ 1.33161157e-04  4.02653976e-03 -9.98382753e+00]\n",
      " [-1.47211344e-06  1.68547735e-06  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Perspective Transform \n",
    "# 2DBox starts from bottom right corner and goes clockwise\n",
    "ppts = np.float32(box)\n",
    "pts = np.float32([[refWidth, 0], [0, 0], [0, refHeight], [refWidth, refHeight]])\n",
    "M = cv2.getPerspectiveTransform(ppts, pts)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'warpPerspective'\n> Overload resolution failed:\n>  - Can't parse 'dsize'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'dsize'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22852/526655366.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarpPerspective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrefWidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrefHeight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) :-1: error: (-5:Bad argument) in function 'warpPerspective'\n> Overload resolution failed:\n>  - Can't parse 'dsize'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'dsize'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "out = cv2.warpPerspective(image, M, (refWidth, refHeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"HERE\", out)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d5ab794ce9c417f502f52bc3779d6ed620da768d06bd54aa69d5807c666f464"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
